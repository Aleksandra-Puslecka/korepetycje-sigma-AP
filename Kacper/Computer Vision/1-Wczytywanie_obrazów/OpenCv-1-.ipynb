{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fed5b18-852c-41ef-9c90-4907e77f743c",
   "metadata": {},
   "source": [
    "# Powtórzenie z lekcji 2\n",
    "## 1. Typy komórek w Jupyter Notebook\n",
    " Code - Komórki służące do pisania i wykonywania kodu.\n",
    " Markdown - Komórki do pisania tekstu.\n",
    "## 2. Po co transformujemy obrazy?\n",
    "#### 2.1. Augmentacja danych\n",
    "Aby zwiększyć różnorodność danych treningowych w uczeniu maszynowym bez potrzeby zbierania nowych obrazów.\n",
    "#### 2.2. Wyostrzenie elementów\n",
    "W celu uwidocznienia kluczowych cech, takich jak krawędzie lub tekstury.\n",
    "#### 2.3. Standaryzacja danych\n",
    "Aby ujednolicić obrazy (rozmiar, wartości pikseli), co poprawia efektywność modeli.\n",
    "#### 2.4. Poprawa czytelności \n",
    "Dla lepszej analizy przez ludzi lub algorytmy (np. redukcja szumu, poprawa kontrastu).\n",
    "#### 2.5. Wzmacnianie ukrytych wzorców\n",
    "Aby wydobyć informacje niewidoczne na pierwszy rzut oka, np. krawędzie.\n",
    "#### 2.6. Zmiana przestrzeni kolorów\n",
    "Dostosowanie obrazu do specyficznych potrzeb analizy, np. konwersja do odcieni szarości.\n",
    "\n",
    "## 3. Jak komputer widzi obrazy?\n",
    "#### Obrazy w kolorze RGB \n",
    "Każdy piksel obrazu ma trzy wartości (R, G, B – czerwony, zielony, niebieski).\n",
    "#### Struktura danych \n",
    "Obrazy to macierze (listy w listach) w Pythonie.\n",
    "\n",
    "###### pixel = [255, 0, 0]  # Czerwony piksel\n",
    "###### image = [[[255, 0, 0], [0, 255, 0]], [[0, 0, 255], [255, 255, 255]]]\n",
    "## 4. Indeksy w listach i slice-y (wycinki list)\n",
    "patrz Python Essential/Listy_Tuple_Sety_Słowniki.ipynb\n",
    "## 5. Floor division (//) i komentarze wielolinijkowe(\"\"\"    \"\"\")\n",
    "## 6. Czym różni się len() od shape?\n",
    "len() -  Zwraca długość pierwszego wymiaru (np. liczba wierszy listy lub macierzy).\n",
    "shape - Atrybut tablic numpy, zwraca pełne wymiary (np. (liczba wierszy, liczba kolumn)).\n",
    "\n",
    "##### import numpy as np\n",
    "##### array = np.array([[1, 2], [3, 4]])\n",
    "##### print(len(array))      # Wynik: 2\n",
    "##### print(array.shape)     # Wynik: (2, 2)\n",
    "## 7. Funkcje pakietu OpenCV\n",
    "imread(): Wczytuje obraz z pliku.\n",
    "imshow(): Wyświetla obraz w osobnym oknie.\n",
    "waitKey(): Zatrzymuje działanie programu, czekając na naciśnięcie klawisza.\n",
    "## 8. Czym dokładnie jest waitKey()?\n",
    "Opis: Funkcja czeka na naciśnięcie klawisza przez użytkownika.\n",
    "Argument w waitKey() określa czas oczekiwania w milisekundach (0 → czeka w nieskończoność).\n",
    "Przydatne przy wyświetlaniu obrazów, aby program nie zamykał okna natychmiast po jego otwarciu - inaczej kod się zatnie lub wyskoczy error bo obraz zamrożony. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdce1e5b",
   "metadata": {},
   "source": [
    "<h1>Tutorial 1 - Point Processing </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031d49de",
   "metadata": {},
   "source": [
    "Point processing is a computer vision technique used to improve or modify an image's visual elements, such as brightness, contrast, and color. Mathematical operations on the image's pixel values are applied to images in order to achieve the intended result. <br></br> In this tutorial we will go through some methods used in point processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63a58a2",
   "metadata": {},
   "source": [
    "<h4>Import Statements</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37bdc8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\user\\anaconda3\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4.10.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install opencv-python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885c65f6",
   "metadata": {},
   "source": [
    "<h2>Exercise 1 </h2>\n",
    "Create a function where you can load any image you want. The function should divide the image into four equal segments. \n",
    "\n",
    "`Using cv2.imshow('image',img);`\n",
    "\n",
    "display the image into the 4 separate segments. To crop specific parts of an image you can use img[0:100, 0:100]. This code will crop the image from the 0 to\n",
    "100 pixels. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3450fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1061\n",
      "(1061, 1920, 3)\n",
      "(531, 961, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image = cv2.imread(\"./Zjecie.png\")\n",
    "\n",
    "#print(image)\n",
    "print(len(image))\n",
    "print(image.shape)\n",
    "x = image.shape[0]//2\n",
    "y = image.shape[1]//2\n",
    "image1 = image[0:531, 0:961]\n",
    "image2 = image[x:image.shape[0], y:image.shape[1]]\n",
    "image3 = image[x:image.shape[0], 0:y]\n",
    "image4 = image[0:x, y:image.shape[1]]\n",
    "\n",
    "print(image1.shape)\n",
    "\n",
    "cv2.imshow(\"Zjecie\",image)\n",
    "cv2.imshow(\"Zjecie1\",image1)\n",
    "cv2.imshow(\"Zjecie2\",image2)\n",
    "cv2.imshow(\"Zjecie3\",image3)\n",
    "cv2.imshow(\"Zjecie4\",image4)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71eaa94b",
   "metadata": {},
   "source": [
    "<h2>Exercise 2</h2>\n",
    "\n",
    "For each of the segments obtained in exercise one, apply a thresholding function to identify if the segment is a dark region or a light region. You may set an arbitrary value for light and dark. (For example greater than intensity of 127 is light).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94127a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread(\"./Zjecie.png\")\n",
    "def grey(image):\n",
    "    image_grey = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    return image_grey\n",
    "def grey2(image):\n",
    "    image_grey = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return image_grey\n",
    "imagegreybgr = grey2(image)\n",
    "imagegreyrgb = grey(image)\n",
    "w,h,k = image.shape\n",
    "\n",
    "r, img = cv2.threshold(imagegreybgr, 70,255,cv2.THRESH_BINARY)\n",
    "\n",
    "cv2.imshow(\"imagegreyrgb\", img)\n",
    "cv2.imshow(\"imagegreybgr\",imagegreybgr)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b591f0",
   "metadata": {},
   "source": [
    "<h2>Exercise 3</h2>\n",
    "\n",
    "Now that you have identified which segments in your image are light or dark. Generate a histogram (between 0 and 255 using bins of 1) for each segment. Compare the segments using the histograms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6651232-8d0c-4f43-abc7-5c6854c4d859",
   "metadata": {},
   "source": [
    "cv2.calcHist([img], [0], None, [256], [0,256], accumulate=False)\n",
    "\n",
    "[img]: Obliczamy histogram dla obrazu.\n",
    "[0]: Bierzemy pod uwagę tylko pierwszy kanał (szary, niebieski, itp.).\n",
    "None: Histogram dotyczy całego obrazu.\n",
    "[256]: Dzielimy wartości pikseli na 256 przedziałów.\n",
    "[0,256]: Analizujemy piksele od 0 do 255.\n",
    "accumulate=False: Histogram zaczyna od pustego stanu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03e8e62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db5538d8",
   "metadata": {},
   "source": [
    "<h2>Exercise 4</h2>\n",
    "\n",
    "Power transform can be used to darken or lighten an image. Create a function that applies power transform to an image. Your function should allow for variability in the value Gamma. Load the segments from the previous exercises and apply power transform to lighten the segments or darken the segments. Compare the transformed segment with the normal segment using histograms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaa5a65",
   "metadata": {},
   "source": [
    "<h2>Exercise 5</h2>\n",
    "\n",
    "Repeat the previous exercise but replace the Power Transform function with bitwise-splicing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1112f4a9",
   "metadata": {},
   "source": [
    "<h2>Exercise 6</h2>\n",
    "\n",
    "Now that you have experimented with different point processing techniques and compared the results using histograms. Let’s apply these techniques tovideo (hopefully in real-time) \n",
    "\n",
    "<ol>\n",
    "  <li>Divide the webcam frame into four equal segments</li>\n",
    "  <li>Using thresholds record which segments are darker.</li>\n",
    "  <li>Apply Power Transform to lighten the darker segments.</li>\n",
    "  <li>Compare the results using histograms (the graph should update as the frames are loading)</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9656668a-cca4-4cf7-8325-e9b4e67ba671",
   "metadata": {},
   "source": [
    "#### 1. Nawiązanie połączenia z kamerą:\n",
    "polacz = cv2.VideoCapture(0)\n",
    "Tworzy obiekt polacz do przechwytywania obrazu z kamery.\n",
    "Argument 0 oznacza pierwszą dostępną kamerę w systemie. Jeśli masz wiele kamer, możesz podać 1, 2 itd.\n",
    "#### 2. Początek pętli przetwarzania obrazu:\n",
    "while True:\n",
    "Pętla while działa w nieskończoność, dopóki nie zostanie przerwana (np. klawiszem d w dalszej części kodu).\n",
    "#### 3. Odczyt obrazu z kamery:\n",
    "ret, frame = polacz.read()\n",
    "polacz.read():\n",
    "ret: Wartość logiczna (True lub False), wskazuje, czy odczyt obrazu się powiódł.\n",
    "frame: Aktualna klatka przechwycona z kamery jako tablica obrazu.\n",
    "#### 4. Obliczanie środka obrazu:\n",
    "h0 = frame.shape[0] // 2\n",
    "h1 = frame.shape[1] // 2\n",
    "frame.shape: Zwraca wymiary obrazu w postaci (wysokość, szerokość, liczba kanałów).\n",
    "h0: Połowa wysokości obrazu (frame.shape[0] to pełna wysokość).\n",
    "h1: Połowa szerokości obrazu (frame.shape[1] to pełna szerokość).\n",
    "Obliczenia dzielą obraz na cztery równe części.\n",
    "#### 5. Tworzenie czterech części obrazu:\n",
    "frame1 = frame[0:h0, 0:h1]\n",
    "frame2 = frame[h0:frame.shape[0], h1:frame.shape[1]]\n",
    "frame3 = frame[0:h0, h1:frame.shape[1]]\n",
    "frame4 = frame[h0:frame.shape[0], 0:h1]\n",
    "Korzystając z indeksowania NumPy, dzielimy obraz na cztery części:\n",
    "frame1: Górny lewy narożnik:\n",
    "Piksele od 0 do h0 w pionie.\n",
    "Piksele od 0 do h1 w poziomie.\n",
    "frame2: Dolny prawy narożnik:\n",
    "Piksele od h0 do końca w pionie (frame.shape[0]).\n",
    "Piksele od h1 do końca w poziomie (frame.shape[1]).\n",
    "frame3: Górny prawy narożnik:\n",
    "Piksele od 0 do h0 w pionie.\n",
    "Piksele od h1 do końca w poziomie.\n",
    "frame4: Dolny lewy narożnik:\n",
    "Piksele od h0 do końca w pionie.\n",
    "Piksele od 0 do h1 w poziomie.\n",
    "#### 6. Wyświetlanie czterech części obrazu:\n",
    "cv2.imshow(\"Webcam 1\", frame1)\n",
    "cv2.imshow(\"Webcam 2\", frame2)\n",
    "cv2.imshow(\"Webcam 3\", frame3)\n",
    "cv2.imshow(\"Webcam 4\", frame4)\n",
    "cv2.imshow: Wyświetla każdą z czterech części obrazu w osobnym oknie.\n",
    "\"Webcam 1\", \"Webcam 2\", itd. to tytuły okien.\n",
    "#### 7. Obsługa zamknięcia okien:\n",
    "if cv2.waitKey(20) & 0xFF == ord(\"d\"):\n",
    "    break\n",
    "cv2.waitKey(20):\n",
    "Oczekuje przez 20 ms na wciśnięcie klawisza.\n",
    "Zwraca kod ASCII wciśniętego klawisza.\n",
    "& 0xFF:\n",
    "Operacja maskowania, która zapewnia kompatybilność z systemami 64-bitowymi.\n",
    "ord(\"d\"):\n",
    "Kod ASCII litery d.\n",
    "Gdy użytkownik wciśnie d, pętla zostaje przerwana.\n",
    "#### 8. Zwolnienie zasobów i zamknięcie okien:\n",
    "polacz.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "polacz.release(): Zwalnia kamerę, umożliwiając jej ponowne użycie przez inne programy.\n",
    "cv2.destroyAllWindows(): Zamykane są wszystkie okna stworzone przez OpenCV.\n",
    "cv2.waitKey(1): Zapewnia płynne zamknięcie okien w niektórych środowiskach.\n",
    "Jak to działa razem?\n",
    "Kamera przechwytuje klatkę wideo.\n",
    "Obraz jest dzielony na cztery części.\n",
    "Każda część obrazu jest wyświetlana w osobnym oknie.\n",
    "Użytkownik może nacisnąć d, aby zakończyć działanie programu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163d397b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
